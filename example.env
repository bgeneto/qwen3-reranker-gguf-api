# model
MODEL_FILENAME=Qwen3-Reranker-4B-q4_k_m.gguf
MODEL_LINK=https://huggingface.co/Mungert/Qwen3-Reranker-4B-GGUF/resolve/main/Qwen3-Reranker-4B-q4_k_m.gguf
N_CTX=32768
N_GPU_LAYERS=-1
N_BATCH=512
N_THREADS=0

# reranking specific (for newer llama-cpp-python versions)
POOLING_TYPE=4
EMBEDDING_MODE=true
# Choose reranking mode: auto, modern, legacy
# auto: try modern first, fallback to legacy
# modern: use pooling-based reranking (newer approach)
# legacy: use logits-based reranking (compatible with older models)
RERANKING_MODE=auto

# logging
LOG_LEVEL=INFO
LOG_TO_FILE=true
LOG_FILE=/srv/logs/reranker.jsonl

# auth
API_TOKEN=your-secret-api-token

# server
HOST=0.0.0.0
PORT=8000

# user permissions (for Docker volume mounts)
# Set these to match your host user to avoid permission issues
# On Linux: UID=$(id -u) GID=$(id -g)
UID=1000
GID=1000
